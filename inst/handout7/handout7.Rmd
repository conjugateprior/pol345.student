---
title: "Handout 7"
author: "Student von Student III"
output:
  pdf_document: default
bibliography: bib/handout7.bib
---

```{r include = FALSE}
library(knitr)
opts_chunk$set(echo = TRUE, comment = "")
```

In this handout, we will learn how to test difference-in-means using the function 
`lm`.  We will include some more practice using loops.

## Topics and Concepts Covered

- Fitting a linear model to estimate a difference-in-means
- Interpreting the coefficients 
- Assessing statistical significance
- Running a loop with the command `for`
- Estimating a difference-in-means using `lm(y ~ x)`
- Using `summary` to return the output from `lm`
- Extracting coefficients, standard errors, t-values, and p-values from `lm`
- Using `rowMeans` and `colMeans` to return the means of the rows or columns 
  of a matrix
- Creating a PDF figure using `pdf`
- Running a file with the command `source`
- Loading an R data file (ending in `.Rdata`) with `load`

**Before beginning this handout, Do not forget to make a new folder for this 
assignment and set your working directory!**

# Using a Linear Model to Test Differences-in-Means

@Gartner2008 explored the relationship between gender and support for the Iraq 
War.  We can state this as a two-sample problem: what is the difference in 
support for the Iraq War between males and females?  Of course, there is 
going to be *some* difference between these two means, so what we 
really want to know is whether the effect is *statistically significant*.  

Statistical significance means, informally, that we can differentiate the 
observed difference from chance error.  A bit more formally, an effect is 
statistically significant at the 5% level  if the probability of observing the 
observed difference in means if, in truth,  there were no effect is 5% or less. 
While the logic may seem, at first, a bit serpentine, a few examples can help 
illustrate how the concepts are used in practice.

We will use the command `lm` to estimate the difference-in-means between two 
groups. `lm` stands for "linear model" which we will be discussing quite a bit. 
The linear model allows a means to test the difference-in-means between two groups, 
but you will see that it can also be used for multivariate regression. 

Recall that a linear regression is a model for the outcome $Y$, of the form
$$
Y_i=\beta_0 +\beta_1 X_i +\epsilon_i
$$
In this model, we are assuming that our observed value $Y_i$ is equal to some 
expected value that depends on the value of $X_i$ plus chance error ($\epsilon_i$). 
So, the expected value of $Y_i$ if $X_i=0$ is $\beta_0$ and the expected value of 
$Y_i$ if $X_i=1$ is  $\beta_0 +\beta_1$.  Therefore, the effect of $X_i$ is 
$\beta_1$.

The linear model returns fitted values of the form where $\widehat\beta_1$ is 
the estimate of the effect of $X_i$ on $Y_i$.  In other words, 
$\widehat \beta_1$ is the estimate of the difference-in-means for $Y_i$ between 
the groups $X_i=1$ and $X_i=0$

In R, we use the `lm` function to fit a linear model.  The `lm` function takes 
a formula of the form `Y ~ X`, where $Y$ is the outcome variable (dependent 
variable) and $X$ is the treatment (independent variable).  Let's start with 
loading in the data.  The data contains the variable `female` which is a 1 
if the respondent is female, and a 0 otherwise, and a variable *mistake* which 
takes a value of 1 if the respondent felt that the Iraq War was a mistake, and a 
0 otherwise.  

First, load and summarize the data:
```{r }
load("data/iraq.RData")
head(iraq)
summary(iraq)
```
To assess the difference-in-means, we are going to fit a linear model, and 
look at it:
```{r }
lm1 <- lm(iraq$mistake ~ iraq$female)
lm1

mean(iraq$mistake[iraq$female == 0]) # Intercept
mean(iraq$mistake[iraq$female == 1]) - 
  mean(iraq$mistake[iraq$female == 0]) # Coefficient
```
We can interpret the first coefficient as the mean for males (`female == 0`), and 
the second coefficient as the difference-in-means between females and males.  In 
other words, women were approximately 4.44 percentage less likely to think the 
Iraq War was a mistake.  

Is the effect statistically significant?  Let's use `summary` to return the 
details from the `lm` object:
```{r }
summary(lm1)
```
We see that it is not.  The $p$-value, in the last column, is approximately 0.21, 
which is not below the standard 5% threshold.   In other words, we cannot reject 
the null hypothesis that the difference between males and females is zero. 

`coef` allows you to access to the coefficients, standard errors, t-statistics, and p-values of the regression:
```{r }
summary(lm1)$coef
```
Then, if we wanted the coefficient and the  p-value for the effect due to 
being female, we would use
```{r }
# One coefficient
summary(lm1)$coef[2,1]
# p-value
summary(lm1)$coef[2,4]
# 95% Confidence interval
mean.iraq <- summary(lm1)$coef[2,1] # Difference in means
se.iraq <- summary(lm1)$coef[2,2] # Standard error
c(mean.iraq - 1.96 * se.iraq, mean.iraq + 1.96 * se.iraq)
``` 

# A Second Example: Growth During Wartime

We turn next to the relationship between civil war and GDP. A broad range 
of literature in International Relations and Comparative Politics explores 
the relationship between civil war and economic growth. The literature has 
argued that the incidence of civil war is often associated with low levels 
of development and economic growth.  

We rely on the `growth.RData` data set. The data set contains the following 
variables:

- `year` - year of observation
- `country` - country
- `war` - binary indicator of civil war (1 if the country 
   experienced civil war in the observed year, 0 else)
- `gdppc` - GDP per capita for the year of observation
- `gdppc.lag` - GDP per capita from the previous year
- `growth.rate` - GDP per capita growth rate, in percentage points

First, we read in the data.
```{r }
load("data/growth.RData") 
head(growth)
summary(growth)
```
To begin, we wish to consider the association between civil war and levels of economic development. As such, we wish to compare the GDP per capita between countries that experienced a war versus those that did not.  We would expect those countries that experience war to have levels of economic development (i.e. measured as GDP per capita) that are significantly lower than countries that do not experience war.  Due to the skew in the data, we must log GDP per capita.
```{r }
growth$log.growth <- log(growth$gdppc) # Log data
lm2 <- lm(growth$log.growth ~ growth$war) # Estimate diff in means
summary(lm2) 
```
We observe that growth rates are lower by about $-0.67$ in countries at war 
versus countries not at war.  The result is statistically significant, since 
the $p$-value on the difference-in-means is much lower than 0.05. 
Therefore, we can reject the null hypothesis that the difference in growth between countries at war and not at war is zero.

That said, is the effect causal?  As you may have guessed, no.  There are any 
number of other possible confounders and omitted variables.  We will start 
discussing how to handle them in the next handout.

# Precept Questions

Recall @Gerber.etal2008a, the social pressure experiment which we discussed in class.  
In this experiment, researchers administered sent one of four different postcards to 
Michigan voters in 2006, as well as maintaining a control group that received 
no such postcard.  The outcome was whether the respondent voted or not.  We will 
be considering the treatment of whether the individual received a postcard 
alerting her to her neighbor's voting behavior and letting her know that her 
neighbors will be made aware of her behavior (1) versus the control condition 
of receiving no postcard.  

In the `data` folder, you will find the file `social.txt`.  

### Question 1

Load in the data.  Was the treatment effect positive or negative?  

```{r}

```

Was it statistically significant?  

```{asis}

```

### Question 3

Construct a 95% and confidence interval.  
```{r}

```

What is the confidence interval telling us?

```{asis}

```

### Question 3

Can we interpret the effect in a causal fashion?  Why or why not?

```{asis}

```

### Question 4

(Practice with a Loop, do what you can with this one, and then we will discuss 
it in precept) 

We're going to continue with some data from the New Haven experiment 
[@Gerber.Green2000] which we 
discussed in the last handout.  You will find in the data folder a file 
called `GerberGreenSubset.txt`, which contains the following variables:

-----------------------------------------------------------------------------
 Name                    Description
 ----------------------- ----------------------------------------------------
 `voted98`               1 if they voted in the 1998 election, 0 otherwise 
                         (dependent variable)
 
 `mailgrp`               1 if they were sent mail encouraging them to vote; 
                         0 otherwise

 `ward`                  Voting ward of household (2, 3, ..., 30)
 
 `appeal`                Type of appeal (1, 2, 3)
 
 `mail`                  Number of mailings sent (0,1,2,3)
-----------------------------------------------------------------------------

You notice that mailings have no significant effect on turnout.  Yet, pretend 
you are a less-than-scrupulous purveyor of campaign mailings.  You get your 
hand on Gerber and Green's data, and do the following:

For every possible combination of number of mailings (1, 2, 3), appeal (1, 2, 3), 
and ward (2, 3,$...$, 30) calculate the treatment effect of receiving the 
mailings and its $p$-value.   (Hint: this is a triple loop.)

```{r}

```

What percentage of your p-values are below 0.05?
```{r}

```

What percentage would you expect by chance?

```{r}

```

Being less-than-scrupulous, you assert that you have found significant results - 
lots of them!  Why should your customers be wary of the claim that mailings 
have an impact?  

```{asis}

```

Explain why this process is termed 'data-fishing' and why it is frowned upon.

```{asis}

```

# References

